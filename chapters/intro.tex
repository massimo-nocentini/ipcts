
\chapter{Introduction}

In this chapter we're going to introduce our work about
understanding coinduction by means of examples; in particular,
we provide Haskell programs, mostly one-liners, to show 
\emph{coinductive} definitions. 

Our work lies on three fundamentals articles by Hinze \cite{Hinze},
Kozen and Silva \cite{Kozen:Silva} and, finally, by Jacobs and Rutten
\cite{jacobs:rutten}: We start with an informal set of notions to 
grasp the underlying idea of \emph{corecursion}, moving to a more 
formal treatment in the last sections. 

\section{Mottos and informal definitions}

A quick search on the net, looking for coinduction and corecursion, 
shows how such concepts aren't acquired and clearly understood as induction and
recursion are; for this reason, many people explain them using mottos 
and informal arguments. The following ones are collected by Micinski 
in \cite{micinski}:
\begin{quote}
    \guillemotleft\,Induction is about finite data, 
        co-induction is about infinite data.\guillemotright\\
    \guillemotleft\,Inductive structures form least fixed points, 
        and coinductive structures form greatest fixed points.\guillemotright\\
    \guillemotleft\,Recursive functions break apart finite data, 
        co-recursive functions build infinite data.\guillemotright
\end{quote}
Additionally, Micinski suggests a path toward understanding coinduction, which
take us to:
\begin{itemize}
    \item study purely functional data structures that rely heavily on the 
        use of laziness to guarantee their amortized bounds;
    \item experiment with a theorem prover, Coq is adviced, that provide
        built-in mechanism to state coinduction definitions;
    \item finally, read a paper by Turner about \emph{total} functional
        programming \cite{turner}.
\end{itemize}

Our personal experience about approaching coinduction from an informal
point, shows that that strategy leads not too far. 
Shortly, we come up with some implementations
using a real programming language that actually allows us to manipulate
infinite objects and, in parallel, coinductive and corecursive definitions. 
Such language is Haskell, a \emph{lazy, purely functional} language.  
This need of clarity, requires us to change our point of view;
in particular, to study the paper by Kozen and Silva for what concern
a formal treatment; and to the paper of Hinze for an implementative one.

\section{A formal approach}

\subsection{Kozen and Silva's work}

A sound and complete formal argument about coinduction is given in the
work of Jacobs and Rutten: they use a categorical approach, introducing
functors, algebras over functors and, in turn, predicates over algebras 
such as \emph{initial} and \emph{final}, describing them by diagrams 
commonly used in category theory, showing homomorphisms and maps, 
respectively.

Sadly, we haven't a sufficient knowledge of category theory to understand
such exposition. Therefore, we turn to practical ones in order to fulfill
our seminar. According to Kozen and Silva, we believe their motto captures
the basic idea underlying coinduction:
\begin{quote}
    \guillemotleft\,A property holds by induction if there is good reason for
    it to hold; whereas a property holds by coinduction if there is no good
    reason for it to \emph{not} hold.\guillemotright
\end{quote}

For any well founded relation $\mathcal{R}$, there exists a valid induction principle and
we usually define $\mathcal{R}$ as the least set satisfying a set of inference rules.
The following is an example where the set $List_{A}$ of \emph{finite} lists over an alphabet $A$,
defined inductively as:
\begin{displaymath}
    {{}\over{nil \in List_{A}}} \quad \frac{a\in A \quad l\in List_{A}}{a:l \in List_{A}}
\end{displaymath}
Previous definition can be rewritten requiring $List_{A}$ to be the
\emph{least} solution of the algebraic \autoref{eq:list:of:a}:
\begin{equation}
    List_{A} = nil + A\times List_{A}
    \label{eq:list:of:a}
\end{equation}
Both definitions allows us to \emph{uniquely} define functions with type $List_{A} \rightarrow B$,
for some type $B$, by \emph{structural induction} on the constructors $nil$ and $:$ (namely $cons$). 
The following are equations defining functions $length$ and $concat$, respectively:
\begin{displaymath}
    \begin{array}{c}
        length\,nil = 0 \\
        length\,(a:l) = 1 + length\,l
    \end{array}
    \quad\quad
    \begin{array}{c}
        concat\,nil\,l = l\\
        concat\,(a:l_{1})\,l_{2} = a:concat\,l_{1}\,l_{2}
    \end{array}
\end{displaymath}
By structural induction, it is possible to prove theorems such as:
\begin{displaymath}
    length(concat\,l_{1}\,l_{2}) = length(l_{1}) + length(l_{2})
\end{displaymath}

On the other hand, coinduction principle is used to prove theorems about
coinductive terms, such as infinite streams and trees; generally speaking,
sets comprising such terms can be defined to be \emph{greatest} solutions
of \autoref{eq:list:of:a}. Using the Haskell programming language, we can
define the coinductive datatype $Stream\,a$, for some type $a$, as follows:
\inputminted[
    mathescape,
    %linenos,
    %numbersep=5pt,
    %gobble=2,
    %frame=lines,
    %framesep=2mm,
    breaklines,
    firstline=91,
    lastline=91
    ]{haskell}{chapters/code/corecursion.hs}
where $hd$ and $tl$ are \emph{destructors}: in order to understand why
each coinductive definition is equipped with them it is necessary to
see type $Stream\,a$ as a coalgebra for the functor $F$ defined as
$F (Stream\,a) = a\times Stream\,a$, where $a$ is a type. 
All such coalgebras have a structure map $(obs, cont)$,
where $obs: Stream\,a \rightarrow a$ and $cont: Stream\,a \rightarrow Stream\,a$,
in this case $obs = hd$ and $cont = tl$, respectively.

Kozen and Silva shows, as their first example, how the \emph{lexicographic} order
on streams can be characterized coinductively and, being of theoretical interest,
we report a short summary.

Let $a$ be a type and $\leq$ be an order relation over it. The ordering $\leq_{lex}$
on $Stream\,a$ is defined to be the \emph{maximum} relation $R\subseteq a\times\,a$ 
such that provided $\rho\,R\,\tau$ holds, then:
\begin{itemize}
    \item $hd\,\rho\leq\,hd\,\tau$ 
    \item $hd\,\rho=\,hd\,\tau \rightarrow (tl\,\rho)\,R\,(tl\,\tau)$ 
\end{itemize}
Ordering $\leq_{lex}$ is required to be the maximum relation since if 
$\lbrace R_{i}\rbrace$ is a collection of relations, each satisfying the above
property, also $\bigcup_{i}\lbrace\,R_{i}\rbrace$ does; therefore, let $\leq_{lex}$
be such union. It is possible to look at $\leq_{lex}$ as the greatest fixed point $R$
of functional $T_{\leq_{lex}}$:
\begin{displaymath}
    T_{\leq_{lex}}\,R = \lbrace (\rho,\tau) : hd\,\rho \leq\,hd\,\tau\wedge\,
        hd\,\rho=\,hd\,\tau\rightarrow\,(tl\,\rho) R (tl\,\tau) \rbrace
\end{displaymath}
formally, $\leq_{lex} = \nu R. T_{\leq_{lex}}\,R$.

\subsection{Hinze's work}

Hinze, on the other hand, focuses on \emph{streams} and, first, provides a coinductive
datatype for them; second, implements operations as corecursive programs; finally,
proofs theorems using coinduction. The main concept of his paper, however, is that
applying some restrictions on Haskell equations defined on streams, allows them
to have \emph{unique solutions}; as a result, Hinze can perform equational
reasoning in a ``coworld'' of terms. In his words:
\begin{quote}
One has to be a bit careful in formulating a recursion equation 
basically avoiding that the sequence
defined swallows its own tail. However, if this care is exercised,
the equation even possesses a unique solution, a fact that is not
very widely appreciated. Uniqueness can be exploited to prove that
two streams are equal: if they satisfy the same recursion equation,
then they are!
\end{quote}
Let $s$ be a stream we would like to define, then the following are 
two counter-examples for restrictions respect to the stated property:
\begin{minted}[escapeinside=||]{haskell}
s = tail s
\end{minted}
and:
\begin{minted}[escapeinside=||]{haskell}
s = Cons (head s) (tail s)
\end{minted}
This is so because both of them have an infinite number of solutions:
every \emph{constant} stream satisfies the former, \emph{every} 
stream satisfies the latter, also called \emph{extensionality}
property. 

The property requested by Hinze can be formalized as:
\begin{minted}[escapeinside=||]{haskell}
x :: Stream a = (h :: a) |$\prec$| (t|$_{x}$| :: Stream a)
\end{minted}
where $x$ is a stream, $h$ is a constant, $t_{x}$ is a term,
namely an expression, possibly containing $s$ and $\prec$ is
a stream constructor; 
finally, neither $h$ nor $t_{x}$ could containg either $head\,x$ or $tail\,x$.
In parallel, a similar property can be stated for functions over streams:
\begin{minted}[escapeinside=||]{haskell}
x x|$_{0}$| |\ldots| x|$_{n}$| :: Stream a -> |\ldots| -> Stream a -> Stream a = 
    (h|$_{x_{0},\ldots,x_{n}}$| :: a) |$\prec$| (t|$_{x,x_{0},\ldots,x_{n}}$| :: Stream a)
\end{minted}
under the restriction that in term $t_{x,x_{0},\ldots,x_{n}}$ cannot be evaluated neither $head$
not $tail$ of any recursive call of function $x$.

According to Hinze, such restrictions on equations over streams allows them
to have unique solutions. Let $\phi$ with type $Stream_{a} \rightarrow Stream_{a}$ 
be a function that produces a term of type $Stream_{a}$, therefore it is possible
to abstract the first of above equations with the following one:
\begin{minted}[escapeinside=||]{haskell}
s = |$\phi$| s
\end{minted}
such that it is admissible. So, it has a \emph{unique} solution, denoted by $fix\,\phi$,
satisfying the following relation:
\begin{minted}[escapeinside=||]{haskell}
fix |$\phi$| = s |$\leftrightarrow$| |$\phi$| s = s
\end{minted}
from left to right it says that $fix\,\phi$ is a solution
of $\phi\,s = s$; from right to left it says that any solution
to $\phi\,s = s$ equals $fix\,\phi$.

We finish with a proof using above concepts: we want to show that
a \emph{constant} stream $c$, such that $c = tail\,c$, has the form $repeat\,k$, for some term $k$:
\begin{minted}[escapeinside=||]{haskell}
c   = head c |$\prec$| tail c   |\text{by extensionality}|
    = head c |$\prec$| c        c |\text{is constant}|
\end{minted}
so $c$ equals the unique solution of $x = head\,c\prec\,x$, 
where $\phi\,x = head\,c\prec\,x$. Therefore $c$ has to be
$repeat(head\,c)$, by definition of $repeat$ (in particular 
look at the $where$ clause):
\begin{minted}[escapeinside=||]{haskell}
repeat a = s where s = a |$\prec$| s
\end{minted}







